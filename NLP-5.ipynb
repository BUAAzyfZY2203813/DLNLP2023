{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假设有一个文本分类任务，数据集包含文本和对应的标签\n",
    "# 定义样本数据\n",
    "data = {\n",
    "    'text': [\n",
    "        'I love this movie',\n",
    "        'This book is amazing',\n",
    "        'The weather is nice today',\n",
    "        'I hate Mondays',\n",
    "        'The food tastes delicious',\n",
    "        'I enjoy playing sports'\n",
    "    ],\n",
    "    'labels': [1, 0, 1, 1, 1, 0]  # 假设1表示正面情绪，0表示负面情绪\n",
    "}\n",
    "\n",
    "# 将数据转换为DataFrame格式\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 划分数据集为训练集、验证集和测试集\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df['text'], df['labels'], test_size=0.2, random_state=42)\n",
    "train_data, valid_data, train_labels, valid_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建训练集、验证集和测试集的DataFrame\n",
    "train_df = pd.DataFrame({'text': train_data, 'labels': train_labels})\n",
    "valid_df = pd.DataFrame({'text': valid_data, 'labels': valid_labels})\n",
    "test_df = pd.DataFrame({'text': test_data, 'labels': test_labels})\n",
    "\n",
    "# 保存数据集为CSV文件\n",
    "train_df.to_csv('train_dataset.csv', index=False)\n",
    "valid_df.to_csv('valid_dataset.csv', index=False)\n",
    "test_df.to_csv('test_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: tf.Tensor(0.7400327, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.25, shape=(), dtype=float32)\n",
      "Epoch: 2\n",
      "Training Loss: tf.Tensor(0.6724488, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.375, shape=(), dtype=float32)\n",
      "Epoch: 3\n",
      "Training Loss: tf.Tensor(0.6705637, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.41666666, shape=(), dtype=float32)\n",
      "Epoch: 4\n",
      "Training Loss: tf.Tensor(0.6443115, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.4375, shape=(), dtype=float32)\n",
      "Epoch: 5\n",
      "Training Loss: tf.Tensor(0.5931341, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.45, shape=(), dtype=float32)\n",
      "Epoch: 6\n",
      "Training Loss: tf.Tensor(0.56010824, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.45833334, shape=(), dtype=float32)\n",
      "Epoch: 7\n",
      "Training Loss: tf.Tensor(0.45180225, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.4642857, shape=(), dtype=float32)\n",
      "Epoch: 8\n",
      "Training Loss: tf.Tensor(0.5483914, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.46875, shape=(), dtype=float32)\n",
      "Epoch: 9\n",
      "Training Loss: tf.Tensor(0.4649309, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.4722222, shape=(), dtype=float32)\n",
      "Epoch: 10\n",
      "Training Loss: tf.Tensor(0.43633986, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "Epoch: 11\n",
      "Training Loss: tf.Tensor(0.4424971, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.52272725, shape=(), dtype=float32)\n",
      "Epoch: 12\n",
      "Training Loss: tf.Tensor(0.38596174, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5416667, shape=(), dtype=float32)\n",
      "Epoch: 13\n",
      "Training Loss: tf.Tensor(0.29939762, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5576923, shape=(), dtype=float32)\n",
      "Epoch: 14\n",
      "Training Loss: tf.Tensor(0.37616435, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5535714, shape=(), dtype=float32)\n",
      "Epoch: 15\n",
      "Training Loss: tf.Tensor(0.36198172, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.56666666, shape=(), dtype=float32)\n",
      "Epoch: 16\n",
      "Training Loss: tf.Tensor(0.34969842, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.578125, shape=(), dtype=float32)\n",
      "Epoch: 17\n",
      "Training Loss: tf.Tensor(0.27738324, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5882353, shape=(), dtype=float32)\n",
      "Epoch: 18\n",
      "Training Loss: tf.Tensor(0.34177947, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5972222, shape=(), dtype=float32)\n",
      "Epoch: 19\n",
      "Training Loss: tf.Tensor(0.29617023, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.6052632, shape=(), dtype=float32)\n",
      "Epoch: 20\n",
      "Training Loss: tf.Tensor(0.25281778, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.6125, shape=(), dtype=float32)\n",
      "Test Accuracy: tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库和模块\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "# 加载BERT模型和Tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# 准备数据集\n",
    "train_data = pd.read_csv('train_dataset.csv') # 准备训练数据\n",
    "valid_data = pd.read_csv('valid_dataset.csv')  # 准备验证数据\n",
    "test_data = pd.read_csv('test_dataset.csv')   # 准备测试数据\n",
    "\n",
    "# 对数据进行编码和转换\n",
    "train_encodings = tokenizer(train_data['text'].tolist(), truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(valid_data['text'].tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_data['labels']\n",
    ")).shuffle(100).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_data['labels']\n",
    ")).shuffle(100).batch(16)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(valid_encodings),\n",
    "    valid_data['labels']\n",
    ")).batch(16)\n",
    "\n",
    "# 定义微调过程的损失函数和优化器\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "# 定义微调过程的评估指标\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "# 定义微调过程的训练步骤\n",
    "@tf.function\n",
    "def train_step(inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(inputs, training=True)\n",
    "        logits = outputs.logits\n",
    "        train_loss = loss(labels, logits)\n",
    "\n",
    "    grads = tape.gradient(train_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    accuracy(labels, logits)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "# 开始微调训练过程\n",
    "for epoch in range(20):\n",
    "    print('Epoch:', epoch+1)\n",
    "    for inputs, labels in train_dataset:\n",
    "        train_loss = train_step(inputs, labels)\n",
    "\n",
    "    for inputs, labels in valid_dataset:\n",
    "        outputs = model(inputs, training=False)\n",
    "        logits = outputs.logits\n",
    "        accuracy(labels, logits)\n",
    "\n",
    "    print('Training Loss:', train_loss)\n",
    "    print('Validation Accuracy:', accuracy.result())\n",
    "\n",
    "# 在测试集上评估模型性能\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "for inputs, labels in test_dataset:\n",
    "    outputs = model(inputs, training=False)\n",
    "    logits = outputs.logits\n",
    "    test_accuracy(labels, logits)\n",
    "\n",
    "print('Test Accuracy:', test_accuracy.result())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: tf.Tensor(0.6976159, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.33333334, shape=(), dtype=float32)\n",
      "Epoch: 2\n",
      "Training Loss: tf.Tensor(0.64643514, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.33333334, shape=(), dtype=float32)\n",
      "Epoch: 3\n",
      "Training Loss: tf.Tensor(0.58924294, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.44444445, shape=(), dtype=float32)\n",
      "Epoch: 4\n",
      "Training Loss: tf.Tensor(0.5715023, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "Epoch: 5\n",
      "Training Loss: tf.Tensor(0.5096499, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.53333336, shape=(), dtype=float32)\n",
      "Epoch: 6\n",
      "Training Loss: tf.Tensor(0.50171643, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5555556, shape=(), dtype=float32)\n",
      "Epoch: 7\n",
      "Training Loss: tf.Tensor(0.40239158, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5714286, shape=(), dtype=float32)\n",
      "Epoch: 8\n",
      "Training Loss: tf.Tensor(0.37016088, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5833333, shape=(), dtype=float32)\n",
      "Epoch: 9\n",
      "Training Loss: tf.Tensor(0.31739342, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5925926, shape=(), dtype=float32)\n",
      "Epoch: 10\n",
      "Training Loss: tf.Tensor(0.27452955, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.6, shape=(), dtype=float32)\n",
      "Test Accuracy: tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2ForSequenceClassification\n",
    "\n",
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = TFGPT2ForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# 准备数据集\n",
    "train_data = pd.read_csv('train_dataset.csv') # 准备训练数据\n",
    "valid_data = pd.read_csv('valid_dataset.csv')  # 准备验证数据\n",
    "test_data = pd.read_csv('test_dataset.csv')   # 准备测试数据\n",
    "\n",
    "# 对数据进行编码和转换\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer.pad_token = '[PAD]'\n",
    "train_encodings = tokenizer(train_data['text'].tolist(), truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(valid_data['text'].tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_data['labels']\n",
    ")).shuffle(100).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_data['labels']\n",
    ")).shuffle(100).batch(16)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(valid_encodings),\n",
    "    valid_data['labels']\n",
    ")).batch(16)\n",
    "\n",
    "# 定义微调过程的损失函数和优化器\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "# 定义微调过程的评估指标\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "# 定义微调过程的训练步骤\n",
    "@tf.function\n",
    "def train_step(inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 将输入序列和目标序列拼接起来\n",
    "        input_sequence = tf.concat([inputs['input_ids'], labels[:, :-1]], axis=1)\n",
    "        target_sequence = labels[:, 1:]\n",
    "\n",
    "        # 计算模型输出\n",
    "        outputs = model(input_sequence, training=True)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # 计算损失\n",
    "        train_loss = loss(target_sequence, logits)\n",
    "\n",
    "    grads = tape.gradient(train_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    accuracy(target_sequence, logits)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "# 开始微调训练过程\n",
    "for epoch in range(10):\n",
    "    print('Epoch:', epoch+1)\n",
    "    for inputs, labels in train_dataset:\n",
    "        train_loss = train_step(inputs, labels)\n",
    "\n",
    "    for inputs, labels in valid_dataset:\n",
    "        outputs = model(inputs, training=False)\n",
    "        logits = outputs.logits\n",
    "        accuracy(labels, logits)\n",
    "\n",
    "    print('Training Loss:', train_loss)\n",
    "    print('Validation Accuracy:', accuracy.result())\n",
    "\n",
    "# 在测试集上评估模型性能\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "for inputs, labels in test_dataset:\n",
    "    outputs = model(inputs, training=False)[0]\n",
    "    logits = outputs.logits\n",
    "    test_accuracy(labels, logits)\n",
    "\n",
    "print('Test Accuracy:', test_accuracy.result())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: tf.Tensor(0.73439735, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "Epoch: 2\n",
      "Training Loss: tf.Tensor(0.60361856, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.625, shape=(), dtype=float32)\n",
      "Epoch: 3\n",
      "Training Loss: tf.Tensor(0.59139115, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.6666667, shape=(), dtype=float32)\n",
      "Epoch: 4\n",
      "Training Loss: tf.Tensor(0.6323643, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.6875, shape=(), dtype=float32)\n",
      "Epoch: 5\n",
      "Training Loss: tf.Tensor(0.6248029, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.7, shape=(), dtype=float32)\n",
      "Epoch: 6\n",
      "Training Loss: tf.Tensor(0.49607703, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.7083333, shape=(), dtype=float32)\n",
      "Epoch: 7\n",
      "Training Loss: tf.Tensor(0.52961534, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.71428573, shape=(), dtype=float32)\n",
      "Epoch: 8\n",
      "Training Loss: tf.Tensor(0.44395247, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.75, shape=(), dtype=float32)\n",
      "Epoch: 9\n",
      "Training Loss: tf.Tensor(0.4314164, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.7777778, shape=(), dtype=float32)\n",
      "Epoch: 10\n",
      "Training Loss: tf.Tensor(0.39353752, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.8, shape=(), dtype=float32)\n",
      "Epoch: 11\n",
      "Training Loss: tf.Tensor(0.37143984, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.8181818, shape=(), dtype=float32)\n",
      "Epoch: 12\n",
      "Training Loss: tf.Tensor(0.32599097, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.8333333, shape=(), dtype=float32)\n",
      "Epoch: 13\n",
      "Training Loss: tf.Tensor(0.3066815, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.84615386, shape=(), dtype=float32)\n",
      "Epoch: 14\n",
      "Training Loss: tf.Tensor(0.25462958, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.85714287, shape=(), dtype=float32)\n",
      "Epoch: 15\n",
      "Training Loss: tf.Tensor(0.2294677, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.8666667, shape=(), dtype=float32)\n",
      "Epoch: 16\n",
      "Training Loss: tf.Tensor(0.2331915, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.875, shape=(), dtype=float32)\n",
      "Epoch: 17\n",
      "Training Loss: tf.Tensor(0.20761059, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.88235295, shape=(), dtype=float32)\n",
      "Epoch: 18\n",
      "Training Loss: tf.Tensor(0.21134813, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.8888889, shape=(), dtype=float32)\n",
      "Epoch: 19\n",
      "Training Loss: tf.Tensor(0.17059247, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.8947368, shape=(), dtype=float32)\n",
      "Epoch: 20\n",
      "Training Loss: tf.Tensor(0.18991315, shape=(), dtype=float32)\n",
      "Validation Accuracy: tf.Tensor(0.9, shape=(), dtype=float32)\n",
      "Test Accuracy: tf.Tensor(0.5, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "\n",
    "# 加载T5模型和Tokenizer\n",
    "model_name = 't5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# 准备数据集\n",
    "train_data = pd.read_csv('train_dataset.csv') # 准备训练数据\n",
    "valid_data = pd.read_csv('valid_dataset.csv')  # 准备验证数据\n",
    "test_data = pd.read_csv('test_dataset.csv')   # 准备测试数据\n",
    "\n",
    "# 对数据进行编码和转换\n",
    "train_encodings = tokenizer(train_data, truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(valid_data, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_data, truncation=True, padding=True)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(valid_encodings),\n",
    "    valid_labels\n",
    ")).batch(16)\n",
    "\n",
    "# 定义微调过程的损失函数和优化器\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "# 定义微调过程的评估指标\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "# 定义微调过程的训练步骤\n",
    "@tf.function\n",
    "def train_step(inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(inputs['input_ids'], labels=labels, training=True)\n",
    "        logits = outputs.logits\n",
    "        train_loss = loss(labels, logits)\n",
    "\n",
    "    grads = tape.gradient(train_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    accuracy(labels, logits)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "# 开始微调训练过程\n",
    "for epoch in range(10):\n",
    "    print('Epoch:', epoch+1)\n",
    "    for inputs, labels in train_dataset:\n",
    "        train_loss = train_step(inputs, labels)\n",
    "\n",
    "    for inputs, labels in valid_dataset:\n",
    "        outputs = model(inputs['input_ids'], labels=labels, training=False)\n",
    "        logits = outputs.logits\n",
    "        accuracy(labels, logits)\n",
    "\n",
    "    print('Training Loss:', train_loss)\n",
    "    print('Validation Accuracy:', accuracy.result())\n",
    "\n",
    "# 在测试集上评估模型性能\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "for inputs, labels in test_dataset:\n",
    "    outputs = model(inputs['input_ids'], training=False)\n",
    "    logits = outputs.logits\n",
    "    test_accuracy(labels, logits)\n",
    "\n",
    "print('Test Accuracy:', test_accuracy.result())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
